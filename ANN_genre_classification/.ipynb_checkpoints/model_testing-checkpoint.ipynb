{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test models that were pretrained on small fma dataset with **Google Colab** (**ANN_genre_classification.upynb**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.HybrydNet_056a import HybrydNet\n",
    "from models.HybrydMlNet114_043 import HybrydMLNet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_coarse = HybrydNet()    # 8 genre model\n",
    "net_other = HybrydMLNet()   # 114 genre model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybrydMLNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(7, 11), stride=(3, 5), padding=(3, 5))\n",
       "  (act1): ReLU()\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (do1): Dropout2d(p=0.05, inplace=False)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1ad): Conv2d(32, 128, kernel_size=(5, 7), stride=(3, 3), padding=(2, 5))\n",
       "  (act1ad): ELU(alpha=1.0)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (do2): Dropout2d(p=0.05, inplace=False)\n",
       "  (pool1ad): AvgPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0)\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): Tanh()\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (do3): Dropout2d(p=0.05, inplace=False)\n",
       "  (pool2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2ad): Conv2d(256, 512, kernel_size=(5, 3), stride=(1, 1), padding=(2, 1))\n",
       "  (act2ad): ReLU()\n",
       "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (do4): Dropout2d(p=0.05, inplace=False)\n",
       "  (pool2ad): AvgPool2d(kernel_size=5, stride=3, padding=2)\n",
       "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (fc1_act): ELU(alpha=1.0)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2_act): ReLU()\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3_act): Tanh()\n",
       "  (fc4): Linear(in_features=256, out_features=114, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_coarse.load_state_dict(torch.load(\"models/HybrydNet_056a.pt\"))\n",
    "net_coarse.eval()\n",
    "\n",
    "net_other.load_state_dict(torch.load(\"models/HybrydMlNet114_043.pt\"))\n",
    "net_other.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to extract features that can be used as model input. In this case it is concatenated **Mel-spectrograms** with **FRAME_SIZE=2048**, **HOP_LENGTH=512**, **90 Mel bands** and **13 MFCCs and their 1st and 2nd derivatives**. Because model was trained on 29.5 sec data, we need to split our custom track to a number of samples of length 29.5 and drop the last fragment that will be less than 29.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import librosa as lb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.8/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "<ipython-input-13-47355f172c91>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds_coarse = list(zip(torch.nn.Softmax()(net_coarse.forward(X))[0].data, classes))\n",
      "<ipython-input-13-47355f172c91>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds_other = list(zip(torch.nn.Softmax()(net_other.forward(X))[0].data, ml_labels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental - Instrumental - Ambient (0.317:0.138:0.068)\n",
      "Experimental - Rock - Noise (0.193:0.157:0.062)\n",
      "Rock - Punk - Metal (0.461:0.079:0.066)\n",
      "Rock - Punk - Garage (0.463:0.109:0.055)\n",
      "Rock - Punk - Garage (0.481:0.092:0.083)\n",
      "Rock - Punk - Metal (0.496:0.086:0.063)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net_coarse.to(device)\n",
    "net_other.to(device)\n",
    "\n",
    "classes = ['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Pop', 'Rock']\n",
    "ml_labels = ['Avant-Garde', 'International', 'Sound Art', 'Novelty', 'Turkish', 'Pop', 'New Age', 'Rock', 'Romany (Gypsy)', 'Electronic', 'Sound Effects', 'Folk', 'Soundtrack', 'Hip-Hop', 'Audio Collage', 'Punk', 'Post-Rock', 'Lo-Fi', 'Compilation', 'Rap', 'Field Recordings', 'Metal', 'Noise', 'Psych-Folk', 'Trip-Hop', 'Breakbeat', 'Krautrock', 'Tango', 'Experimental', 'Dance', 'Electroacoustic', 'Chip Music', 'Ambient Electronic', 'Hip-Hop Beats', 'Loud-Rock', 'Latin America', 'Drone', 'Salsa', 'Free-Folk', 'Noise-Rock', 'Psych-Rock', 'Goth', 'Electro-Punk', 'Indie-Rock', 'Abstract Hip-Hop', 'Industrial', 'No Wave', 'Experimental Pop', 'French', 'Reggae - Dub', 'Drum & Bass', 'Afrobeat', 'Nerdcore', 'Garage', 'Indian', 'New Wave', 'Post-Punk', 'Reggae - Dancehall', 'Sludge', 'African', 'Freak-Folk', 'Progressive', 'Alternative Hip-Hop', 'Death-Metal', 'Middle East', 'Singer-Songwriter', 'Shoegaze', 'Kid-Friendly', 'Synth Pop', 'Spanish', 'Ambient', 'Hardcore', 'Thrash', 'Power-Pop', 'Space-Rock', 'Polka', 'Balkan', 'Unclassifiable', 'Europe', 'Chill-out', 'Bigbeat', 'Surf', 'Black-Metal', 'Christmas', 'Brazilian', 'Asia-Far East', 'South Indian Traditional', 'Celtic', 'British Folk', 'Techno', 'House', 'Glitch', 'Rock Opera', 'Breakcore - Hard', 'Minimal Electronic', 'Sound Poetry', 'Grindcore', 'Jungle', 'Minimalism', 'Instrumental', 'Dubstep', 'North African', 'Sound Collage', 'Klezmer', 'Flamenco', 'Skweee', 'IDM', 'Downtempo', 'Chiptune', 'Cumbia', 'Musique Concrete', 'Latin', 'Improv', 'Holiday']\n",
    "\n",
    "\n",
    "track_file = \"a.mp3\"    # Enter path to file which you want to analyze\n",
    "signal, sr = lb.load(track_file)\n",
    "\n",
    "song_coarse_preds = []\n",
    "song_other_preds = []\n",
    "\n",
    "for i in range(signal.size // 650475):\n",
    "    mel_spec = lb.feature.melspectrogram(signal[650475*i:650475*(i+1)], sr=sr, n_fft=2048, hop_length=512, n_mels=90)\n",
    "    log_mel_spec = lb.power_to_db(mel_spec)\n",
    "\n",
    "    mfcc = lb.feature.mfcc(signal[650475*i:650475*(i+1)], n_mfcc=13)\n",
    "    mfcc2 = lb.feature.delta(mfcc)\n",
    "    mfcc3 = lb.feature.delta(mfcc, order=2)\n",
    "    mfcc = np.concatenate((mfcc, mfcc2, mfcc3))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(np.concatenate((mfcc, log_mel_spec))).unsqueeze(0).to(device)\n",
    "        preds_coarse = list(zip(torch.nn.Softmax()(net_coarse.forward(X))[0].data, classes))\n",
    "        preds_coarse.sort(reverse=True)\n",
    "        song_coarse_preds.append(preds_coarse)\n",
    "\n",
    "        preds_other = list(zip(torch.nn.Softmax()(net_other.forward(X))[0].data, ml_labels))\n",
    "        preds_other.sort(reverse=True)\n",
    "        song_other_preds.append(preds_other)\n",
    "        print(preds_other[0][1], \"-\", preds_other[1][1], \"-\", preds_other[2][1], f\"({preds_other[0][0]:.3f}:{preds_other[1][0]:.3f}:{preds_other[2][0]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top1_genre - Top2_genre - Top3_genre (**corresponding Softmax values**)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
